{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Context-free Parsing and Derivative Scanning\n",
    "\n",
    "This Jove file covers two topics. \n",
    "\n",
    "* The first, context-free parsing, helps us design a parser for regular expressions. This\n",
    "is the subject of Chapter 11. \n",
    "\n",
    "* The second is derivative-based scanning, the topic for Chapter 10\n",
    "\n",
    "These are now described. \n",
    "\n",
    "You may wish to watch the video before embarking on this work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# This Youtube video walks through this notebook\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('xGvCjoWemWg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Context-free Parsing\n",
    "\n",
    "We will present the parser for regular expressions\n",
    "\n",
    "* The CFG for regular expressions that we'd like to deal with (during derivative-based scanning) \n",
    "is the one shown below. \n",
    "\n",
    "* Note that the rule for AND and for NOT are not implemented (these \n",
    "are exercises for the reader)\n",
    "\n",
    "\n",
    "expression -> expression PLUS catexp\n",
    "\n",
    "catexp -> catexp andexp | andexp \n",
    "\n",
    "andexp -> andexp AND ordyexp | ordyexp\n",
    "\n",
    "ordyexp -> str | eps | LPAREN expression RPAREN | ordyexp STAR | NOT ordyexp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path[0:0] = ['../..','../../3rdparty'] # Put these at the head of the search path\n",
    "\n",
    "from lex import lex\n",
    "from yacc import yacc\n",
    "from jove.StateNameSanitizers import ResetStNum, NxtStateStr\n",
    "from jove.SystemImports       import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Token definitions\n",
    "\n",
    "This is the lexer for REs. We begin with token definitions\n",
    "\n",
    "**NOTE** \n",
    "\n",
    "* We leave it as an exercise for you to add the token for negation and conjunction, below\n",
    "\n",
    "i.e. support things like !a for negation and !a & b for conjunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "tokens = ('EPS','STR','LPAREN','RPAREN','PLUS','STAR') #, 'NOT', 'AND')\n",
    "\n",
    "# Tokens\n",
    "t_PLUS    = r'\\+'\n",
    "t_STAR    = r'\\*'\n",
    "t_LPAREN  = r'\\('\n",
    "t_RPAREN  = r'\\)'\n",
    "t_EPS     = r'\\'\\'|\\\"\\\"'  # Not allowing @ for empty string anymore! # t_EPS = r'\\@'\n",
    "t_STR     = r'[a-zA-Z0-9]'\n",
    "#t_NOT     = ADD THE REGULAR EXPRESSION FOR NEGATION HERE    <== add this as an exercise\n",
    "#t_AND     = ADD THE REGULAR EXPRESSION FOR CONJUNCTION HERE <== add this\n",
    "\n",
    "# Ignored characters\n",
    "t_ignore = \" \\t\"\n",
    "\n",
    "def t_newline(t):\n",
    "    r'\\n+'\n",
    "    t.lexer.lineno += t.value.count(\"\\n\")\n",
    "    \n",
    "def t_error(t):\n",
    "    print(\"Illegal character '%s'\" % t.value[0])\n",
    "    t.lexer.skip(1)\n",
    "    \n",
    "# Build the lexer if necessary\n",
    "# lex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### These parsing rules specify many things. \n",
    "\n",
    "We begin with operator precedence rules that are essentially to help the \"LALR parser\" (also known as the bottom-up parser) resolve 'shift-reduce conflicts'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Parsing rules\n",
    "\n",
    "# A4J: Suggested new precedence rules for AND and NOT are in comments below.\n",
    "# Uncomment the AND and NOT lines in your extension\n",
    "# \n",
    "precedence = (\n",
    "   ('left','PLUS'),\n",
    "#   ('left', 'AND'),   <== ADD these after checking that this is what you want\n",
    "   ('left','STAR'),\n",
    "#   ('right','NOT')    <== ADD these after checking that this is what you want\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### CFG productions and semantic actions\n",
    "\n",
    "These Python functions whose names begin with \"p_\" house (1) the CFG production rules within their documentation strings. (2) the semantic actions within their body. The semantic actions can refer to grammar symbol attributes within CFG productions. We will explain one of these rules now.\n",
    "\n",
    "Take the rules \n",
    "\n",
    " expression -> expression PLUS catexp\n",
    " expression -> catexp\n",
    " \n",
    "1) This function defines the first production rule\n",
    "\n",
    "def p_expression_plus(t):\n",
    "\n",
    "   a) This comment string expresses the production rule\n",
    "   \n",
    "    '''expression : expression PLUS catexp'''\n",
    "    \n",
    "   b) This line below tells us that the occurrence of 'expression' on\n",
    "      the left-hand side is marked t[0], and its value is determined by\n",
    "      applying function attrDyadicInfix onto its three arguments below.\n",
    "      Here, t[1] is the attribute of 'expression' coming after the colon (:)\n",
    "      and the attribute of catexp is t[3]\n",
    "      \n",
    "    t[0] = attrDyadicInfix(\"+\", t[1], t[3])    \n",
    "    \n",
    "2) This function expresses the second related production rule where the\n",
    "   basis case \n",
    "    \n",
    "def p_expression_plus1(t):\n",
    "    '''expression : catexp'''\n",
    "\n",
    "    t[0] = t[1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def p_expression_plus(t):\n",
    "    'expression : expression PLUS catexp'\n",
    "    #\n",
    "    t[0] = attrDyadicInfix(\"+\", t[1], t[3])    \n",
    "    \n",
    "def p_expression_plus1(t):\n",
    "    'expression : catexp'\n",
    "    #\n",
    "    t[0] = t[1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def p_expression_cat(t):\n",
    "    'catexp :  catexp andexp'\n",
    "    #\n",
    "    t[0] = attrDyadicInfix(\".\", t[1], t[2])\n",
    "\n",
    "def p_expression_cat1(t):\n",
    "    'catexp :  andexp'\n",
    "    #\n",
    "    t[0] = t[1]  \n",
    "\n",
    "'''\n",
    "def p_expression_ordy(t):          <== Suitably add these in\n",
    "    'andexp : andexp AND ordyexp'  <== to support infix and\n",
    "    #\n",
    "    t[0] = attrDyadicInfix(\"&\", t[1], t[3])\n",
    "'''\n",
    "\n",
    "def p_expression_ordy1(t):\n",
    "    'andexp : ordyexp'\n",
    "    #\n",
    "    t[0] = t[1]\n",
    "\n",
    "# We employ field 'ast' of the dict to record the abstract syntax tree. \n",
    "# Field 'dig' holds a digraph. It too is a dict. \n",
    "# Its fields are nl for the node list and el for the edge list\n",
    "\n",
    "def p_expression_ordy_star(t):\n",
    "    'ordyexp : ordyexp STAR'\n",
    "    #\n",
    "    ast = ('*', t[1]['ast'])\n",
    "\n",
    "    nlin = t[1]['dig']['nl']\n",
    "    elin = t[1]['dig']['el']\n",
    "    \n",
    "    rootin = nlin[0]\n",
    "\n",
    "    root = NxtStateStr(\"R*_\") \n",
    "    right = NxtStateStr(\"*_\")\n",
    "\n",
    "    t[0] = {'ast' : ast,\n",
    "            'dig' : {'nl' : [root] + nlin + [right], # this order important for proper layout!\n",
    "                     'el' : elin + [ (root, rootin),\n",
    "                                     (root, right) ]\n",
    "                    }}\n",
    "\n",
    "'''\n",
    "def p_expression_ordy_not(t):  <== when you add \"NOT\", the tree-drawing methods are built here\n",
    "    'ordyexp : NOT ordyexp'\n",
    "    #\n",
    "    ast  = ('!', t[2]['ast'])\n",
    "    \n",
    "    nlin = t[2]['dig']['nl']\n",
    "    elin = t[2]['dig']['el']\n",
    "    \n",
    "    rootin = nlin[0]\n",
    "\n",
    "    root = NxtStateStr(\"!R_\") \n",
    "    left = NxtStateStr(\"!_\")\n",
    "\n",
    "    t[0] = {'ast' : ast,\n",
    "            'dig' : {'nl' : [ root, left ] + nlin, # this order important for proper layout!\n",
    "                     'el' : elin + [ (root, left),\n",
    "                                     (root, rootin) ]\n",
    "                    }}\n",
    "'''\n",
    "    \n",
    "def p_expression_ordy_paren(t):\n",
    "    'ordyexp : LPAREN expression RPAREN'\n",
    "    #\n",
    "    ast  = t[2]['ast']\n",
    "    \n",
    "    nlin = t[2]['dig']['nl']\n",
    "    elin = t[2]['dig']['el']\n",
    "    \n",
    "    rootin = nlin[0]\n",
    "    \n",
    "    root = NxtStateStr(\"(R)_\")\n",
    "    left = NxtStateStr(\"(_\")\n",
    "    right= NxtStateStr(\")_\")\n",
    "    \n",
    "    t[0] = {'ast' : ast,\n",
    "            'dig' : {'nl' : [root, left] + nlin + [right], #order important f. proper layout!\n",
    "                     'el' : elin + [ (root, left),\n",
    "                                     (root, rootin),\n",
    "                                     (root, right) ]\n",
    "                    }}\n",
    "\n",
    "def p_expression_ordy_eps(t):\n",
    "    'ordyexp : EPS'\n",
    "    #\n",
    "    strn = '@'\n",
    "    ast  = ('@', strn)           \n",
    "    t[0] = { 'ast' : ast,\n",
    "             'dig' : {'nl' : [ strn + NxtStateStr(\"_\") ],\n",
    "                      'el' : []\n",
    "                     }}          \n",
    "    \n",
    "def p_expression_ordy_str(t):\n",
    "    'ordyexp : STR'\n",
    "    #\n",
    "    strn = t[1]\n",
    "    ast  = ('str', strn)\n",
    "    t[0] = {'ast' : ast,\n",
    "            'dig' : {'nl' : [ strn + NxtStateStr(\"_\") ],\n",
    "                     'el' : [] \n",
    "                    }}\n",
    "\n",
    "def p_error(t):\n",
    "    print(\"Syntax error at '%s'\" % t.value)\n",
    "\n",
    "#--\n",
    "    \n",
    "def attrDyadicInfix(op, attr1, attr3):         # <== this is what prints the parse-tree\n",
    "    ast  = (op, (attr1['ast'], attr3['ast']))  # <== for an infix operator\n",
    "    \n",
    "    nlin1 = attr1['dig']['nl']\n",
    "    nlin3 = attr3['dig']['nl']\n",
    "    nlin  = nlin1 + nlin3\n",
    "    \n",
    "    elin1 = attr1['dig']['el']\n",
    "    elin3 = attr3['dig']['el']\n",
    "    elin  = elin1 + elin3\n",
    "    \n",
    "    rootin1 = nlin1[0]\n",
    "    rootin3 = nlin3[0]    \n",
    "    \n",
    "    root   = NxtStateStr(\"R1\"+op+\"R2\"+\"_\") # NxtStateStr(\"$_\")\n",
    "    left   = rootin1\n",
    "    middle = NxtStateStr(op+\"_\")\n",
    "    right  = rootin3\n",
    "    \n",
    "    return {'ast' : ast,\n",
    "            'dig' : {'nl' : [ root, left, middle, right ] + nlin,\n",
    "                     'el' : elin + [ (root, left),\n",
    "                                     (root, middle),\n",
    "                                     (root, right) ]\n",
    "                     }}\n",
    "\n",
    "#===\n",
    "# This is the main function in this Jove file. Give\n",
    "#===\n",
    "\n",
    "def parseRE(s):\n",
    "    \"\"\"In: a string s containing a regular expression.\n",
    "       Out: An attribute triple consisting of\n",
    "            1) An abstract syntax tree suitable for processing in the derivative-based scanner\n",
    "            2) A node-list for the parse-tree digraph generated. Good for drawing a parse tree \n",
    "               using the drawPT function below\n",
    "            3) An edge list for the parse-tree generated (again good for drawing using the\n",
    "               drawPT function below)\n",
    "    \"\"\"\n",
    "    mylexer  = lex()\n",
    "    myparser = yacc()\n",
    "    pt = myparser.parse(s, lexer = mylexer)             # <== pass the right lexer into the parser\n",
    "    return (pt['ast'], pt['dig']['nl'], pt['dig']['el']) # <== the parser returns the parse-tree\n",
    "                                                        # <== as a Python data structure, plus a tree data structure for drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def drawPT(ast_nl_el, comment=\"PT\"):\n",
    "    \"\"\"Given an (ast, nl, el) triple where nl is the node and el the edge-list,\n",
    "       draw the Parse Tree by returning a dot object.\n",
    "    \"\"\"\n",
    "    (ast, nl, el) = ast_nl_el\n",
    "    print(\"Drawing AST for \", ast)\n",
    "    dotObj_pt = Digraph(comment)\n",
    "    dotObj_pt.graph_attr['rankdir'] = 'TB'\n",
    "    for n in nl:\n",
    "        prNam = n.split('_')[0]\n",
    "        dotObj_pt.node(n, prNam, shape=\"oval\", peripheries=\"1\")\n",
    "    for e in el:\n",
    "        dotObj_pt.edge(e[0], e[1])\n",
    "    return dotObj_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Exercise: Study of Parsing by Drawing Parse Trees\n",
    "\n",
    "** Question Q1(a): ** Some simple parse-tree examples are now given. Please produce three more interesting-looking parser-trees of your own. They can be anything, but ensure that you understand the trees generated. Write two short sentences describing each such parse-tree produced. Try to limit yourself to about eight leaf nodes and about the same number of operators (rough guideline only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "drawPT(parseRE(\"''\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "drawPT(parseRE(\"1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "drawPT(parseRE(\"(0*1*)*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "** Your answer for Q1(a) below **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Exercise: Produce the Parse Tree for an RE, and Explain \n",
    "\n",
    "** Q1(b): ** Draw the parse tree for \"0+11*\" and explain its shape. Does it implement precedences that you expect \"naturally\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "drawPT(parseRE(\"0+11*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "** Your answer for Q1(b) here: ** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Exercise : RE parsing : Precedences\n",
    "\n",
    "Q1(c): Create variants of the expression \"0+11*\" by putting parentheses, and describe the parse-trees obtained. For example, calling the above RE R1, we have\n",
    "\n",
    "* R1 = \"0+11*\"\n",
    "\n",
    "* R2 = \"(0+1)1*\" is one variant.\n",
    "\n",
    "Similarly, produce two other variants, calling them R3 and R4 merely by placing parentheses differently.\n",
    "\n",
    "* Argue that R1 through R4 denote different languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "** Your answer for Q1(c) below **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Produce parse-trees for extended REs\n",
    "\n",
    "** Q1(d): **  Turn on the parsing rules for \"!\" and \"&\". Test these three regular expressions on the following REs\n",
    "\n",
    "* RE with * and ! : \"a!b*\"\n",
    "\n",
    "* RE with & involved : \"cd&ef\"\n",
    "\n",
    "* RE with & and + involved : \"a+b&c+d\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "** Your answer for Q1(d) below **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Derivative-based Pattern Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#=== Now comes derivMatch as illustration of RE Derivative scanning\n",
    "\n",
    "# These four functions are simple extractors of the operator and arguments\n",
    "\n",
    "def opr(E):\n",
    "    \"\"\"Retrieves the operator of an expression.\n",
    "    \"\"\"\n",
    "    return E[0]\n",
    "\n",
    "def arg1(E):\n",
    "    \"\"\"Retrieves the first argument of a binary operator-based expression.\n",
    "    \"\"\"\n",
    "    return E[1][0]\n",
    "\n",
    "def arg2(E):\n",
    "    \"\"\"Retrieves the second argument of a binary operator-based expression.\n",
    "    \"\"\"\n",
    "    return E[1][1]\n",
    "\n",
    "def arg(E):\n",
    "    \"\"\"Retrieves the only argument of a unary operator-based expression.\n",
    "    \"\"\"\n",
    "    return E[1]\n",
    "\n",
    "def nullable(E):\n",
    "    \"\"\"This is the nullability test defined in Chapter 10.\n",
    "    \"\"\"\n",
    "    if (opr(E) == \"str\") :\n",
    "        return False\n",
    "    elif (opr(E) == '@') :\n",
    "        return True\n",
    "    elif (opr(E) == \"mty\") :\n",
    "        return False\n",
    "    elif (opr(E) == \"*\"):\n",
    "        return True\n",
    "#    elif (opr(E) == \"!\"):\n",
    "#        return not nullable(arg(E))\n",
    "    elif (opr(E) == '+') :\n",
    "        return nullable(arg1(E)) or nullable(arg2(E))\n",
    "    elif (opr(E) == '.') :\n",
    "        return nullable(arg1(E)) and nullable(arg2(E))\n",
    "#    elif (opr(E) == '&') :\n",
    "#        return nullable(arg1(E)) and nullable(arg2(E))\n",
    "    else:\n",
    "        return \"???\"    \n",
    "\n",
    "def dv(E, c):\n",
    "    \"\"\"This function computes the derivative\n",
    "       of a regular expression E with respect\n",
    "       to character \"c\".\n",
    "    \"\"\"\n",
    "    if (opr(E) == \"str\") :\n",
    "        if (arg(E) == c):\n",
    "            return ('@', '@')\n",
    "        else:\n",
    "            return (\"mty\", \"mty\")\n",
    "    elif (opr(E) == '@') :\n",
    "        return (\"mty\", \"mty\")\n",
    "    elif (opr(E) == \"mty\") :\n",
    "        return (\"mty\", \"mty\")\n",
    "    elif (opr(E) == \"*\"):\n",
    "        return (\".\", (dv(arg(E), c), E))\n",
    "    elif (opr(E) == \"!\"):\n",
    "        return (\"!\", dv(arg(E), c))\n",
    "    elif (opr(E) == '+') :\n",
    "        return (\"+\", (dv(arg1(E), c), dv(arg2(E), c)))\n",
    "    elif (opr(E) == '&') :\n",
    "        return (\"&\", (dv(arg1(E), c), dv(arg2(E), c)))\n",
    "    elif (opr(E) == '.') :\n",
    "        if nullable(arg1(E)):\n",
    "            return (\"+\", ( ('.', (dv(arg1(E), c), arg2(E))), dv(arg2(E), c) ))\n",
    "        else:\n",
    "            return ('.', (dv(arg1(E), c), arg2(E)))\n",
    "    else:\n",
    "        return \"???\"        \n",
    "\n",
    "def matches(w, E):\n",
    "    if w==\"\":\n",
    "        return nullable(E)\n",
    "    else:\n",
    "        derivative = dv(E, w[0])\n",
    "        return matches(w[1:], derivative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = \"(a+bc+def+bd)*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawPT(parseRE(RE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS AN ILLEGAL CALL. YOU HAVE TO FEED THE AST TO \"matches\"\n",
    "matches(\"bc\",RE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ast,a,b) = parseRE(RE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches(\"bc\", ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches(\"b\",ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Testing Derivative-based Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Testing Nullability\n",
    "\n",
    "A regular expression is nullable if its language contains epsilon.\n",
    "Regular-expression based pattern-matching works as follows:\n",
    "\n",
    "* Keep obtaining the derivatives of a given RE under the characters comprising a string\n",
    "\n",
    "* When the string is empty, check whether the RE is nullable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is '' nullable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "drawPT(parseRE(\"''\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Returns the Python expression E as a tree\n",
    "# Also returns the node list nl\n",
    "# and the edge list el\n",
    "\n",
    "(E, nl, el) = parseRE(\"''\")\n",
    "nullable(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parseRE(\"''\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "el"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is \"c\" nullable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawPT(parseRE(\"c\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "(E, nl, el) = parseRE(\"c\")\n",
    "nullable(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Is c* nullable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawPT(parseRE(\"c*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "(E, nl, el) = parseRE(\"c*\")\n",
    "nullable(E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THIS CELL BELOW WILL WORK AFTER YOU IMPLEMENT NEGATION \n",
    "\n",
    "You will get an error \"illegal character !\". But you can implement negation\n",
    "and then it will be handled fine.\n",
    "\n",
    "Ditto implementing conjunction also\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "(E, nl, el) = parseRE(\"!c*\")\n",
    "nullable(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
