{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Context-free Parsing and Derivative Scanning which generates proofs\n",
    "\n",
    "## This is a version of CH10_Derivatives.ipynb that also prints out a proof as to why an RE matched a string. It follows the rules given in Figure 10.2.  **NOTE** I forgot to include a rule for ```&``` -- i.e. AND. The rule is similar to that for ```+``` and is present in the code. Since I did not have a rule number for ```&```, I call it Rule-10 (Figure 10.2 has Rules 1-9).\n",
    "\n",
    "\n",
    "This Jove file covers two topics. \n",
    "\n",
    "* The first, context-free parsing, helps us design a parser for regular expressions. This\n",
    "is the subject of Chapter 11. \n",
    "\n",
    "* The second is derivative-based scanning, the topic for Chapter 10\n",
    "\n",
    "These are now described. \n",
    "\n",
    "You may wish to watch the video before embarking on this work.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# This Youtube video walks through this notebook\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('xGvCjoWemWg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Context-free Parsing\n",
    "\n",
    "We will present the parser for regular expressions\n",
    "\n",
    "* The CFG for regular expressions that we'd like to deal with (during derivative-based scanning) \n",
    "is the one shown below. \n",
    "\n",
    "* Note that the rule for AND and for NOT are not implemented (these \n",
    "are exercises for the reader)\n",
    "\n",
    "\n",
    "expression -> expression PLUS catexp\n",
    "\n",
    "catexp -> catexp andexp | andexp \n",
    "\n",
    "andexp -> andexp AND ordyexp | ordyexp\n",
    "\n",
    "ordyexp -> str | eps | LPAREN expression RPAREN | ordyexp STAR | NOT ordyexp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "import sys\n",
    "\n",
    "# -- Detect if in Own Install or in Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    OWN_INSTALL = False\n",
    "except:\n",
    "    OWN_INSTALL = True\n",
    "    \n",
    "if OWN_INSTALL:\n",
    "    \n",
    "  #---- Leave these definitions ON if running on laptop\n",
    "  #---- Else turn OFF by putting them between ''' ... '''\n",
    "\n",
    "  sys.path[0:0] = ['../../../../..',  '../../../../../3rdparty',  \n",
    "                   '../../../..',  '../../../../3rdparty',  \n",
    "                   '../../..',     '../../../3rdparty', \n",
    "                   '../..',        '../../3rdparty',\n",
    "                   '..',           '../3rdparty' ]\n",
    "\n",
    "else: # In colab\n",
    "  ! if [ ! -d Jove ]; then git clone https://github.com/ganeshutah/Jove Jove; fi\n",
    "  sys.path.append('./Jove')\n",
    "  sys.path.append('./Jove/jove')\n",
    "\n",
    "# -- common imports --\n",
    "from jove.lex import lex\n",
    "from jove.yacc import yacc\n",
    "from jove.StateNameSanitizers import ResetStNum, NxtStateStr\n",
    "from jove.SystemImports       import *\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### Token definitions\n",
    "\n",
    "This is the lexer for REs. We begin with token definitions\n",
    "\n",
    "**NOTE** \n",
    "\n",
    "* We leave it as an exercise for you to add the token for negation and conjunction, below\n",
    "\n",
    "i.e. support things like !a for negation and !a & b for conjunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "tokens = ('EPS','STR','LPAREN','RPAREN','PLUS','STAR', 'NOT', 'AND')\n",
    "\n",
    "# Tokens\n",
    "t_PLUS    = r'\\+'\n",
    "t_STAR    = r'\\*'\n",
    "t_LPAREN  = r'\\('\n",
    "t_RPAREN  = r'\\)'\n",
    "t_EPS     = r'\\'\\'|\\\"\\\"'   \n",
    "t_STR     = r'[a-zA-Z0-9]'\n",
    "t_NOT     = r'\\!' \n",
    "t_AND     = r'\\&'\n",
    "\n",
    "# Ignored characters\n",
    "t_ignore = \" \\t\"\n",
    "\n",
    "def t_newline(t):\n",
    "    r'\\n+'\n",
    "    t.lexer.lineno += t.value.count(\"\\n\")\n",
    "    \n",
    "def t_error(t):\n",
    "    print(\"Illegal character '%s'\" % t.value[0])\n",
    "    t.lexer.skip(1)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### These parsing rules specify many things. \n",
    "\n",
    "We begin with operator precedence rules that are essentially to help the \"LALR parser\" (also known as the bottom-up parser) resolve 'shift-reduce conflicts'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Parsing rules\n",
    "# \n",
    "precedence = (\n",
    "   ('left','PLUS'),\n",
    "   ('left', 'AND'),   #<== ADDED this \n",
    "   ('left','STAR'),\n",
    "   ('right','NOT')    #<== ADDED this\n",
    "   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "### CFG productions and semantic actions\n",
    "\n",
    "These Python functions whose names begin with \"p_\" house (1) the CFG production rules within their documentation strings. (2) the semantic actions within their body. The semantic actions can refer to grammar symbol attributes within CFG productions. We will explain one of these rules now.\n",
    "\n",
    "Take the rules \n",
    "\n",
    " expression -> expression PLUS catexp\n",
    " expression -> catexp\n",
    " \n",
    "1) This function defines the first production rule\n",
    "\n",
    "def p_expression_plus(t):\n",
    "\n",
    "   a) This comment string expresses the production rule\n",
    "   \n",
    "    '''expression : expression PLUS catexp'''\n",
    "    \n",
    "   b) This line below tells us that the occurrence of 'expression' on\n",
    "      the left-hand side is marked t[0], and its value is determined by\n",
    "      applying function attrDyadicInfix onto its three arguments below.\n",
    "      Here, t[1] is the attribute of 'expression' coming after the colon (:)\n",
    "      and the attribute of catexp is t[3]\n",
    "      \n",
    "    t[0] = attrDyadicInfix(\"+\", t[1], t[3])    \n",
    "    \n",
    "2) This function expresses the second related production rule where the\n",
    "   basis case \n",
    "    \n",
    "def p_expression_plus1(t):\n",
    "    '''expression : catexp'''\n",
    "\n",
    "    t[0] = t[1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def p_expression_plus(t):\n",
    "    'expression : expression PLUS catexp'\n",
    "    #\n",
    "    t[0] = attrDyadicInfix(\"+\", t[1], t[3])    \n",
    "    \n",
    "def p_expression_plus1(t):\n",
    "    'expression : catexp'\n",
    "    #\n",
    "    t[0] = t[1]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def p_expression_cat(t):\n",
    "    'catexp :  catexp andexp'\n",
    "    #\n",
    "    t[0] = attrDyadicInfix(\".\", t[1], t[2])\n",
    "\n",
    "def p_expression_cat1(t):\n",
    "    'catexp :  andexp'\n",
    "    #\n",
    "    t[0] = t[1]  \n",
    "\n",
    "\n",
    "def p_expression_ordy(t):          #<== Added this\n",
    "    'andexp : andexp AND ordyexp'  #<== to support infix and\n",
    "    #\n",
    "    t[0] = attrDyadicInfix(\"&\", t[1], t[3])\n",
    "\n",
    "\n",
    "def p_expression_ordy1(t):\n",
    "    'andexp : ordyexp'\n",
    "    #\n",
    "    t[0] = t[1]\n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "    Documentation for p_expression_ordy_star:\n",
    "    \n",
    "    We employ field 'ast' of the dict to record the abstract syntax tree. \n",
    "    Field 'dig' holds a digraph. It too is a dict. \n",
    "    Its fields are nl for the node list and el for the edge list\n",
    "    '''\n",
    "    \n",
    "def p_expression_ordy_star(t):\n",
    "    'ordyexp : ordyexp STAR'\n",
    "    #\n",
    "    ast = ('*', t[1]['ast'])\n",
    "\n",
    "    nlin = t[1]['dig']['nl']\n",
    "    elin = t[1]['dig']['el']\n",
    "    \n",
    "    rootin = nlin[0]\n",
    "\n",
    "    root = NxtStateStr(\"R*_\") \n",
    "    right = NxtStateStr(\"*_\")\n",
    "\n",
    "    t[0] = {'ast' : ast,\n",
    "            'dig' : {'nl' : [root] + nlin + [right], # this order important for proper layout!\n",
    "                     'el' : elin + [ (root, rootin),\n",
    "                                     (root, right) ]\n",
    "                    }}\n",
    "\n",
    "\n",
    "def p_expression_ordy_not(t):  #<== The tree-drawing for NOT happens here\n",
    "    'ordyexp : NOT ordyexp'\n",
    "    #\n",
    "    ast  = ('!', t[2]['ast'])\n",
    "    \n",
    "    nlin = t[2]['dig']['nl']\n",
    "    elin = t[2]['dig']['el']\n",
    "    \n",
    "    rootin = nlin[0]\n",
    "\n",
    "    root = NxtStateStr(\"!R_\") \n",
    "    left = NxtStateStr(\"!_\")\n",
    "\n",
    "    t[0] = {'ast' : ast,\n",
    "            'dig' : {'nl' : [ root, left ] + nlin, # this order important for proper layout!\n",
    "                     'el' : elin + [ (root, left),\n",
    "                                     (root, rootin) ]\n",
    "                    }}\n",
    "\n",
    "    \n",
    "def p_expression_ordy_paren(t):\n",
    "    'ordyexp : LPAREN expression RPAREN'\n",
    "    #\n",
    "    ast  = t[2]['ast']\n",
    "    \n",
    "    nlin = t[2]['dig']['nl']\n",
    "    elin = t[2]['dig']['el']\n",
    "    \n",
    "    rootin = nlin[0]\n",
    "    \n",
    "    root = NxtStateStr(\"(R)_\")\n",
    "    left = NxtStateStr(\"(_\")\n",
    "    right= NxtStateStr(\")_\")\n",
    "    \n",
    "    t[0] = {'ast' : ast,\n",
    "            'dig' : {'nl' : [root, left] + nlin + [right], #order important f. proper layout!\n",
    "                     'el' : elin + [ (root, left),\n",
    "                                     (root, rootin),\n",
    "                                     (root, right) ]\n",
    "                    }}\n",
    "\n",
    "def p_expression_ordy_eps(t):\n",
    "    'ordyexp : EPS'\n",
    "    #\n",
    "    strn = '@'\n",
    "    ast  = ('@', strn)           \n",
    "    t[0] = { 'ast' : ast,\n",
    "             'dig' : {'nl' : [ strn + NxtStateStr(\"_\") ],\n",
    "                      'el' : []\n",
    "                     }}          \n",
    "    \n",
    "def p_expression_ordy_str(t):\n",
    "    'ordyexp : STR'\n",
    "    #\n",
    "    strn = t[1]\n",
    "    ast  = ('str', strn)\n",
    "    t[0] = {'ast' : ast,\n",
    "            'dig' : {'nl' : [ strn + NxtStateStr(\"_\") ],\n",
    "                     'el' : [] \n",
    "                    }}\n",
    "\n",
    "def p_error(t):\n",
    "    print(\"Syntax error at '%s'\" % t.value)\n",
    "\n",
    "#--\n",
    "    \n",
    "def attrDyadicInfix(op, attr1, attr3):         # <== this is what prints the parse-tree\n",
    "    ast  = (op, (attr1['ast'], attr3['ast']))  # <== for an infix operator\n",
    "    \n",
    "    nlin1 = attr1['dig']['nl']\n",
    "    nlin3 = attr3['dig']['nl']\n",
    "    nlin  = nlin1 + nlin3\n",
    "    \n",
    "    elin1 = attr1['dig']['el']\n",
    "    elin3 = attr3['dig']['el']\n",
    "    elin  = elin1 + elin3\n",
    "    \n",
    "    rootin1 = nlin1[0]\n",
    "    rootin3 = nlin3[0]    \n",
    "    \n",
    "    root   = NxtStateStr(\"R1\"+op+\"R2\"+\"_\") # NxtStateStr(\"$_\")\n",
    "    left   = rootin1\n",
    "    middle = NxtStateStr(op+\"_\")\n",
    "    right  = rootin3\n",
    "    \n",
    "    return {'ast' : ast,\n",
    "            'dig' : {'nl' : [ root, left, middle, right ] + nlin,\n",
    "                     'el' : elin + [ (root, left),\n",
    "                                     (root, middle),\n",
    "                                     (root, right) ]\n",
    "                     }}\n",
    "\n",
    "#===\n",
    "# This is the entry-point into the parser.\n",
    "#===\n",
    "\n",
    "def parseRE(s):\n",
    "    \"\"\"In: a string s containing a regular expression.\n",
    "       Out: An attribute triple consisting of\n",
    "            1) An abstract syntax tree suitable for processing in the derivative-based scanner\n",
    "            2) A node-list for the parse-tree digraph generated. Good for drawing a parse tree \n",
    "               using the drawPT function below\n",
    "            3) An edge list for the parse-tree generated (again good for drawing using the\n",
    "               drawPT function below)\n",
    "    \"\"\"\n",
    "    mylexer  = lex()\n",
    "    myparser = yacc()\n",
    "    pt = myparser.parse(s, lexer = mylexer)             # <== pass the right lexer into the parser\n",
    "    return (pt['ast'], pt['dig']['nl'], pt['dig']['el']) # <== the parser returns the parse-tree\n",
    "                                                        # <== as a Python data structure, plus a tree data structure for drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def drawPT(ast_nl_el, comment=\"PT\"):\n",
    "    \"\"\"Given an (ast, nl, el) triple where nl is the node and el the edge-list,\n",
    "       draw the Parse Tree by returning a dot object.\n",
    "    \"\"\"\n",
    "    (ast, nl, el) = ast_nl_el\n",
    "    print(\"Drawing AST for \", ast)\n",
    "    dotObj_pt = Digraph(comment)\n",
    "    dotObj_pt.graph_attr['rankdir'] = 'TB'\n",
    "    for n in nl:\n",
    "        prNam = n.split('_')[0]\n",
    "        dotObj_pt.node(n, prNam, shape=\"oval\", peripheries=\"1\")\n",
    "    for e in el:\n",
    "        dotObj_pt.edge(e[0], e[1])\n",
    "    return dotObj_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Exercise: Study of Parsing by Drawing Parse Trees\n",
    "\n",
    "** Question Q1(a): ** Some simple parse-tree examples are now given. Please produce three more interesting-looking parser-trees of your own. They can be anything, but ensure that you understand the trees generated. Write two short sentences describing each such parse-tree produced. Try to limit yourself to about eight leaf nodes and about the same number of operators (rough guideline only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "drawPT(parseRE(\"''\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "parseRE('\"\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parseRE('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parseRE(\"a*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parseRE('a&b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parseRE('ab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parseRE(\"!a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parseRE('!a* b*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "drawPT(parseRE(\"1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "drawPT(parseRE(\"(0*1*)*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "drawPT(parseRE(\"0+11*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Derivative-based Pattern Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#=== Now comes derivMatch as illustration of RE Derivatives and Pattern-matching\n",
    "# These four functions are simple extractors of the operator and arguments\n",
    "\n",
    "def opr(E):\n",
    "    \"\"\"Retrieves the operator of an expression.\n",
    "    \"\"\"\n",
    "    return E[0]\n",
    "\n",
    "def arg1(E):\n",
    "    \"\"\"Retrieves the first argument of a binary operator-based expression.\n",
    "    \"\"\"\n",
    "    return E[1][0]\n",
    "\n",
    "def arg2(E):\n",
    "    \"\"\"Retrieves the second argument of a binary operator-based expression.\n",
    "    \"\"\"\n",
    "    return E[1][1]\n",
    "\n",
    "def arg(E):\n",
    "    \"\"\"Retrieves the only argument of a unary operator-based expression.\n",
    "    \"\"\"\n",
    "    return E[1]\n",
    "\n",
    "def nullable(E):\n",
    "    \"\"\"This is the nullability test defined in Chapter 10.\n",
    "    \"\"\"\n",
    "    if (opr(E) == \"str\") :\n",
    "        return False\n",
    "    elif (opr(E) == '@') :\n",
    "        return True\n",
    "    elif (opr(E) == \"mty\") :\n",
    "        return False\n",
    "    elif (opr(E) == \"*\"):\n",
    "        return True\n",
    "    elif (opr(E) == \"!\"):\n",
    "        return not nullable(arg(E))\n",
    "    elif (opr(E) == '+') :\n",
    "        return nullable(arg1(E)) or nullable(arg2(E))\n",
    "    elif (opr(E) == '.') :\n",
    "        return nullable(arg1(E)) and nullable(arg2(E))\n",
    "    elif (opr(E) == '&') :\n",
    "        return nullable(arg1(E)) and nullable(arg2(E))\n",
    "    else:\n",
    "        return \"??? Undefined expression given to the nullability test. ??? \"    \n",
    "\n",
    "#--- Computes the derivative of E w.r.t. c. \n",
    "#--- Also returns a list of recursive steps executed to produce the derivative, \n",
    "#--- suitably decorated with the Rule numbers and other helpful debugging info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dyadicstr(E, L, ch, R, ind):\n",
    "    return (L + prt(arg1(E),ind) + ch + prt(arg2(E),ind) + R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prt(E, ind):\n",
    "    if opr(E)=='str':\n",
    "        return(arg(E))\n",
    "    elif opr(E) in ['+', '&']:\n",
    "        return dyadicstr(E, '(', opr(E), ')',ind)\n",
    "    elif opr(E)=='.':\n",
    "        return dyadicstr(E, '(', ' ', ')',ind)\n",
    "    elif opr(E)=='mty':\n",
    "        return '{}'\n",
    "    elif opr(E)=='!':\n",
    "        return '!' + '(' + prt(arg(E),ind) + ')'\n",
    "    elif opr(E)=='*':\n",
    "        return '(' + prt(arg(E),ind) + ')' + '*'\n",
    "    elif opr(E)=='@':\n",
    "        return '@'\n",
    "    else:\n",
    "        return \"??? illegal opr(E) for prt. ???\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def dv(E, c, ind):\n",
    "    \"\"\"This function computes the derivative\n",
    "       of a regular expression E with respect\n",
    "       to character \"c\".  \n",
    "    \"\"\"\n",
    "    if (opr(E) == \"str\") :\n",
    "        if (arg(E) == c):\n",
    "            Dout = ('@', '@')\n",
    "            return ( Dout,\n",
    "                     [ ' '*ind + 'Rule 1: Expn ' + prt(E,ind) + ' ~~' + c + '~~> ' + prt(Dout,ind) + '\\n' ] )\n",
    "        else:\n",
    "            Dout = (\"mty\", \"mty\") \n",
    "            return ( Dout,\n",
    "                     [ ' '*ind + 'Rule 2: Expn ' + prt(E,ind) + ' ~~' + c + '~~> ' + prt(Dout,ind) + '\\n' ] )\n",
    "        \n",
    "    elif (opr(E) == '@') :\n",
    "        Dout = (\"mty\", \"mty\")\n",
    "        return ( Dout,\n",
    "                 [ ' '*ind +'Rule 3: Expn ' + prt(E,ind) + ' ~~' + c + '~~> ' + prt(Dout,prt) + '\\n' ] )\n",
    "    \n",
    "    elif (opr(E) == \"mty\") :\n",
    "        Dout = (\"mty\", \"mty\")\n",
    "        return ( Dout,\n",
    "                 [ ' '*ind + 'Rule 4: Expn ' + prt(E,ind) + ' ~~' + c + '~~> ' + prt(Dout,prt) + '\\n' ] )\n",
    "    \n",
    "    elif (opr(E) == \"*\"):\n",
    "        (D, P) = dv(arg(E), c, ind+4)\n",
    "        Dout   = (\".\", (D, E))\n",
    "        return ( Dout,\n",
    "                 [ ' '*ind + 'Rule 5: Expn ' + prt(E,ind) + ' ~~' + c + '~~> ' + prt(Dout,ind) + '\\n' ] + P )\n",
    "    \n",
    "    elif (opr(E) == \"!\"):\n",
    "        (D, P) = dv(arg(E), c, ind+4)\n",
    "        Dout   = (\"!\", D)\n",
    "        return ( Dout,\n",
    "                 [ ' '*ind + 'Rule 6: Expn ' + prt(E,ind) + ' ~~' + c + '~~> ' + prt(Dout,ind) + '\\n' ] + P )\n",
    "    \n",
    "    elif (opr(E) == '+') :\n",
    "        (D1, P1) = dv(arg1(E), c, ind+4)\n",
    "        (D2, P2) = dv(arg2(E), c, ind+4)\n",
    "        Dout     = (\"+\", (D1, D2))\n",
    "        return ( Dout,\n",
    "                  [ ' '*ind + 'Rule 7: Expn ' + prt(E,ind) + ' ~~' + c + '~~> ' + prt(Dout,ind) + '\\n' ] \n",
    "                +  P1 \n",
    "                +  P2 )\n",
    "    \n",
    "    elif (opr(E) == '&') :\n",
    "        (D1, P1) = dv(arg1(E), c, ind+4)\n",
    "        (D2, P2) = dv(arg2(E), c, ind+4)\n",
    "        Dout     = (\"&\", (D1, D2))\n",
    "        return ( Dout,\n",
    "                  [ ' '*ind + 'Rule 10: Expn ' + prt(E,ind) + ' ~~' + c + '~~> ' + prt(Dout,ind) + '\\n' ] \n",
    "                +  P1\n",
    "                +  P2 )    \n",
    "    \n",
    "    elif (opr(E) == '.') :\n",
    "        if nullable(arg1(E)):\n",
    "            (D1, P1) = dv(arg1(E), c, ind+4)\n",
    "            (D2, P2) = dv(arg2(E), c, ind+4) \n",
    "            Dout     = (\"+\", \n",
    "                             ( ('.', (D1, \n",
    "                                      arg2(E)\n",
    "                                     )),\n",
    "                                D2\n",
    "                             ))\n",
    "            return ( Dout,\n",
    "                      [ ' '*ind + 'Rule 8: Nullable ' + prt( arg1(E),ind ) + \" :: \" \n",
    "                         + prt(E,ind) + ' ~~' + c + '~~> ' + prt(Dout,ind) + '\\n' ] \n",
    "                    +  P1 \n",
    "                    +  P2 )    \n",
    "        \n",
    "        else:\n",
    "            (D1, P1) = dv(arg1(E), c, ind+4)\n",
    "            Dout     = ('.', (D1, arg2(E)))\n",
    "            return ( Dout,\n",
    "                      [ ' '*ind + 'Rule 9: !Nullable ' + prt( arg1(E),ind ) + \" :: \" \n",
    "                         + prt(E,ind) + ' ~~' + c + '~~> ' + prt(Dout,ind) + '\\n' ] \n",
    "                    +  P1 )\n",
    "                    \n",
    "    else:\n",
    "        return \"??? Undefined operator in Expn given to dv. ???\"        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def matches(w, E):\n",
    "    if w==\"\":\n",
    "        print(\"----- Derivatives of all characters over; subjecting final derivative to nullability test -----\")\n",
    "        n = nullable(E)\n",
    "        if n:\n",
    "            print(\"-- Final derivative \", prt(E,0), \" is nullable, hence the given RE matches the given string :-)\")\n",
    "        else:\n",
    "            print(\"-- Final derivative \", prt(E,0), \" is not nullable, hence the given RE does not match the given string :-(\")\n",
    "    \n",
    "    else:\n",
    "        print(\"----- Taking derivative of first/next character\", w[0], \"-----\")\n",
    "        (D, P) = dv(E, w[0], 0) # indent of 0\n",
    "        for x in P:\n",
    "            print(x)\n",
    "        return matches(w[1:], D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = \"a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = \"a+b&c\"\n",
    "(ast, n, e) = parseRE(RE)\n",
    "matches(\"zb\", ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = \"a+b* & c*+d\"\n",
    "(ast, n, e) = parseRE(RE)\n",
    "matches(\"aab\", ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = \"!b*\"  \n",
    "(ast, n, e) = parseRE(RE)\n",
    "matches(\"aba\", ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = \"(ab+a)*\"  \n",
    "(ast, n, e) = parseRE(RE)\n",
    "matches(\"aba\", ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = \"(a&!b)\"  \n",
    "(ast, n, e) = parseRE(RE)\n",
    "matches(\"a\", ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = \"(!a&!b)\"  \n",
    "(ast, n, e) = parseRE(RE)\n",
    "matches(\"ah\", ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = \"!(a*)\"  \n",
    "(ast, n, e) = parseRE(RE)\n",
    "matches(\"ab\", ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE = \"(p+q)*\"\n",
    "(ast, n, e) = parseRE(RE)\n",
    "matches(\"pq\",ast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
