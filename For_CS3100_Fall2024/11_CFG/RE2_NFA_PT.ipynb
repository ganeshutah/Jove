{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjRVCVO3v-EB"
      },
      "source": [
        "## Resources on PLY\n",
        "\n",
        "\n",
        "## Documentation of PLY is here: https://www.dabeaz.com/ply/ply.html\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DeNfLbdv-EK"
      },
      "source": [
        "## This Youtube video is a talk by David Beazley, the author of PLY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLHNPaA_v-EL"
      },
      "outputs": [],
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "# Direct path is https://youtu.be/zJ9z6Ge-vXs\n",
        "YouTubeVideo('zJ9z6Ge-vXs')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgXJlPVqv-EN"
      },
      "source": [
        " ## This Youtube video is a talk on creating a calculator using PLY\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3dMyRGZv-EO"
      },
      "outputs": [],
      "source": [
        "from IPython.display import YouTubeVideo\n",
        "# Direct path is  https://youtu.be/Hh49BXmHxX8\n",
        "YouTubeVideo('Hh49BXmHxX8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUu8ICVGv-EO"
      },
      "source": [
        "# THIS NOTEBOOK is referenced in Asg-6\n",
        "# It Creates a RegExp Parser + Draw Parse Trees\n",
        "\n",
        "# YOUR QUESTIONS are at the end!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "IbliX8WZv-EP"
      },
      "outputs": [],
      "source": [
        "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "import sys\n",
        "\n",
        "# -- Detect if in Own Install or in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    OWN_INSTALL = False\n",
        "except:\n",
        "    OWN_INSTALL = True\n",
        "\n",
        "if OWN_INSTALL:\n",
        "\n",
        "  #---- Leave these definitions ON if running on laptop\n",
        "  #---- Else turn OFF by putting them between ''' ... '''\n",
        "\n",
        "  sys.path[0:0] = ['../../../../..',  '../../../../../3rdparty',\n",
        "                   '../../../..',  '../../../../3rdparty',\n",
        "                   '../../..',     '../../../3rdparty',\n",
        "                   '../..',        '../../3rdparty',\n",
        "                   '..',           '../3rdparty' ]\n",
        "\n",
        "else: # In colab\n",
        "  ! if [ ! -d Jove ]; then git clone https://github.com/ganeshutah/Jove Jove; fi\n",
        "  sys.path.append('./Jove')\n",
        "  sys.path.append('./Jove/jove')\n",
        "\n",
        "# -- common imports --\n",
        "from jove.lex import lex\n",
        "from jove.yacc import yacc\n",
        "\n",
        "from jove.StateNameSanitizers import ResetStNum, NxtStateStr\n",
        "from jove.SystemImports       import *\n",
        "\n",
        "from jove.Def_NFA import mk_nfa\n",
        "from jove.DotBashers import *\n",
        "\n",
        "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "KwppFU5ev-EQ"
      },
      "outputs": [],
      "source": [
        "tokens = ('EPS','STR','LPAREN','RPAREN','PLUS','STAR')\n",
        "\n",
        "# Tokens in our RE are these\n",
        "t_EPS     = r'\\'\\'|\\\"\\\"'  # Not allowing @ for empty string anymore! # t_EPS = r'\\@'\n",
        "\n",
        "# The following allows one lower-case, one upper-case or one digit to be used in our REs\n",
        "t_STR     = r'[a-zA-Z0-9]'\n",
        "\n",
        "t_LPAREN  = r'\\('\n",
        "t_RPAREN  = r'\\)'\n",
        "\n",
        "t_PLUS    = r'\\+'\n",
        "t_STAR    = r'\\*'\n",
        "\n",
        "\n",
        "\n",
        "# Ignored characters\n",
        "t_ignore = \" \\t\"\n",
        "\n",
        "def t_newline(t):\n",
        "    r'\\n+'\n",
        "    t.lexer.lineno += t.value.count(\"\\n\")\n",
        "\n",
        "def t_error(t):\n",
        "    print(\"Illegal character '%s'\" % t.value[0])\n",
        "    t.lexer.skip(1)\n",
        "\n",
        "\n",
        "def p_expression_plus(t):\n",
        "    'expression : expression PLUS catexp'\n",
        "    #\n",
        "    nfa = mk_plus_nfa(t[1]['nfa'], t[3]['nfa']) # Union of the two NFAs is returned\n",
        "    tree = attrDyadicInfix(\"+\", t[1], t[3])\n",
        "    tree.update({'nfa':nfa})\n",
        "    t[0] = tree\n",
        "\n",
        "\n",
        "def p_expression_plus1(t):\n",
        "    'expression : catexp'\n",
        "    #\n",
        "    t[0] = t[1]\n",
        "\n",
        "def p_expression_cat(t):\n",
        "    'catexp :  catexp ordyexp'\n",
        "    #\n",
        "    nfa = mk_cat_nfa(t[1]['nfa'], t[2]['nfa'])\n",
        "    #--insert new field 'nfa'\n",
        "    tree = attrDyadicInfix(\".\", t[1], t[2])\n",
        "    tree.update({'nfa':nfa})\n",
        "    t[0] = tree\n",
        "\n",
        "def p_expression_cat1(t):\n",
        "    'catexp :  ordyexp'\n",
        "    #\n",
        "    t[0] = t[1]\n",
        "\n",
        "# We employ field 'ast' of the dict to record the abstract syntax tree.\n",
        "# Field 'dig' holds a digraph. It too is a dict.\n",
        "# Its fields are nl for the node list and el for the edge list\n",
        "\n",
        "def p_expression_ordy_star(t):\n",
        "    'ordyexp : ordyexp STAR'\n",
        "    #\n",
        "    nfa = mk_star_nfa(t[1]['nfa'])\n",
        "\n",
        "    ast = ('*', t[1]['ast'])\n",
        "    nlin = t[1]['dig']['nl']\n",
        "    elin = t[1]['dig']['el']\n",
        "\n",
        "    rootin = nlin[0]\n",
        "\n",
        "    root = NxtStateStr(\"R*_\")\n",
        "    right = NxtStateStr(\"*_\")\n",
        "\n",
        "    t[0] = {'nfa' : nfa,\n",
        "            'ast' : ast,\n",
        "            'dig' : {'nl' : [root] + nlin + [right], # this order important for proper layout!\n",
        "                     'el' : elin + [ (root, rootin),\n",
        "                                     (root, right) ]\n",
        "                    }}\n",
        "\n",
        "def p_expression_ordy_paren(t):\n",
        "    'ordyexp : LPAREN expression RPAREN'\n",
        "    #\n",
        "    nfa  = t[2]['nfa']\n",
        "\n",
        "    ast  = t[2]['ast']\n",
        "    nlin = t[2]['dig']['nl']\n",
        "    elin = t[2]['dig']['el']\n",
        "\n",
        "    rootin = nlin[0]\n",
        "\n",
        "    root = NxtStateStr(\"(R)_\")\n",
        "    left = NxtStateStr(\"(_\")\n",
        "    right= NxtStateStr(\")_\")\n",
        "\n",
        "    t[0] = {'nfa' : nfa,\n",
        "            'ast' : ast,\n",
        "            'dig' : {'nl' : [root, left] + nlin + [right], #order important f. proper layout!\n",
        "                     'el' : elin + [ (root, left),\n",
        "                                     (root, rootin),\n",
        "                                     (root, right) ]\n",
        "                    }}\n",
        "\n",
        "def p_expression_ordy_eps(t):\n",
        "    'ordyexp : EPS'\n",
        "    #\n",
        "    strn = '@'\n",
        "    ast  = ('@', strn)\n",
        "    t[0] = { 'nfa' : mk_eps_nfa(),\n",
        "             'ast' : ast,\n",
        "             'dig' : {'nl' : [ strn + NxtStateStr(\"_\") ],\n",
        "                      'el' : []\n",
        "                     }}\n",
        "\n",
        "def p_expression_ordy_str(t):\n",
        "    'ordyexp : STR'\n",
        "    #\n",
        "    str = t[1]\n",
        "    nfa_STR = mk_symbol_nfa(t[1])\n",
        "    ast  = ('str', str)\n",
        "    t[0] = {'nfa' : nfa_STR,\n",
        "            'ast' : ast,\n",
        "            'dig' : {'nl' : [ str + NxtStateStr(\"_\") ],\n",
        "                     'el' : []\n",
        "                    }}\n",
        "\n",
        "def p_error(t):\n",
        "    print(\"Syntax error at '%s'\" % t.value)\n",
        "\n",
        "#--\n",
        "def parseRE(s):\n",
        "    \"\"\"In: a string s containing a regular expression.\n",
        "       Out: An attribute quadruple (nfa,ast,nodelist,edgelist)\n",
        "    \"\"\"\n",
        "    mylexer  = lex()\n",
        "    myparser = yacc()\n",
        "    #-- pass the right lexer into the parser\n",
        "    p = myparser.parse(s, lexer = mylexer)\n",
        "    return (p['nfa'], p['ast'], p['dig']['nl'], p['dig']['el'])\n",
        "\n",
        "#--\n",
        "def mk_plus_nfa(N1, N2):\n",
        "    \"\"\"Given two NFAs, return their union.\n",
        "    \"\"\"\n",
        "    delta_accum = dict({})\n",
        "    delta_accum.update(N1[\"Delta\"])\n",
        "    delta_accum.update(N2[\"Delta\"]) # Simply accumulate the transitions\n",
        "    # The alphabet is inferred bottom-up; thus we must union the Sigmas\n",
        "    # of the NFAs!\n",
        "    return mk_nfa(Q     = N1[\"Q\"] | N2[\"Q\"],\n",
        "                  Sigma = N1[\"Sigma\"] | N2[\"Sigma\"],\n",
        "                  Delta = delta_accum,\n",
        "                  Q0    = N1[\"Q0\"] | N2[\"Q0\"],\n",
        "                  F     = N1[\"F\"] | N2[\"F\"])\n",
        "\n",
        "def mk_cat_nfa(N1, N2):\n",
        "    '''Given two NFAs, return their concatenation.\n",
        "    '''\n",
        "    delta_accum = dict({})\n",
        "    delta_accum.update(N1[\"Delta\"])\n",
        "    delta_accum.update(N2[\"Delta\"])\n",
        "    # Now, introduce moves from every one of N1's final states\n",
        "    # to the set of N2's initial states.\n",
        "    for f in N1[\"F\"]:\n",
        "        # However, N1's final states may already have epsilon moves to\n",
        "        # other N1-states!\n",
        "        # Expand the target of such jumps to include N2's Q0 also!\n",
        "        if (f, \"\") in N1[\"Delta\"]:\n",
        "            delta_accum.update({ (f,\"\"):(N2[\"Q0\"] | N1[\"Delta\"][(f, \"\")])\n",
        "                               })\n",
        "        else:\n",
        "            delta_accum.update({ (f, \"\"): N2[\"Q0\"] })\n",
        "    # In syntax-directed translation, it is impossible\n",
        "    # that N2 and N1 have common states. Check anyhow\n",
        "    # in case there are bugs elsewhere that cause it.\n",
        "    assert((N2[\"F\"] & N1[\"F\"]) == set({}))\n",
        "    return mk_nfa(Q     = N1[\"Q\"] | N2[\"Q\"],\n",
        "                  Sigma = N1[\"Sigma\"] | N2[\"Sigma\"],\n",
        "                  Delta = delta_accum,\n",
        "                  Q0    = N1[\"Q0\"],\n",
        "                  F     = N2[\"F\"])\n",
        "\n",
        "\n",
        "def mk_star_nfa(N):\n",
        "    '''Given an NFA, make its star.\n",
        "    '''\n",
        "    # Follow construction from Kozen's book:\n",
        "    # 1) Introduce new (single) start+final state IF\n",
        "    # 2) Let Q0 = set({ IF })\n",
        "    # 2) Move on epsilon from IF to the set N[Q0]\n",
        "    # 3) Make N[F] non-final\n",
        "    # 4) Spin back from every state in N[F] to Q0\n",
        "    #\n",
        "    delta_accum = dict({})\n",
        "    IF = NxtStateStr()\n",
        "    Q0 = set({ IF }) # new set of start + final states\n",
        "    # Jump from IF to N's start state set\n",
        "    delta_accum.update({ (IF,\"\"): N[\"Q0\"] })\n",
        "    delta_accum.update(N[\"Delta\"])\n",
        "    #\n",
        "    for f in N[\"F\"]:\n",
        "        # N's final states may already have epsilon moves to\n",
        "        # other N-states!\n",
        "        # Expand the target of such jumps to include Q0 also.\n",
        "        if (f, \"\") in N[\"Delta\"]:\n",
        "            delta_accum.update({ (f, \"\"): (Q0 | N[\"Delta\"][(f, \"\")]) })\n",
        "        else:\n",
        "            delta_accum.update({ (f, \"\"): Q0 })\n",
        "    #\n",
        "    return mk_nfa(Q     = N[\"Q\"] | Q0,\n",
        "                  Sigma = N[\"Sigma\"],\n",
        "                  Delta = delta_accum,\n",
        "                  Q0    = Q0,\n",
        "                  F     = Q0)\n",
        "\n",
        "\n",
        "def mk_eps_nfa():\n",
        "    \"\"\"An nfa with exactly one start+final state, which is the NFA for Epsilon.\n",
        "    \"\"\"\n",
        "    Q0 = set({ NxtStateStr() })\n",
        "    F  = Q0\n",
        "    return mk_nfa(Q     = Q0,\n",
        "                  Sigma = set({}),\n",
        "                  Delta = dict({}),\n",
        "                  Q0    = Q0,\n",
        "                  F     = Q0)\n",
        "\n",
        "def mk_symbol_nfa(a):\n",
        "    \"\"\"The NFA for a single re letter.\n",
        "    \"\"\"\n",
        "    # Make a fresh initial state\n",
        "    q0 = NxtStateStr()\n",
        "    Q0 = set({ q0 })\n",
        "    # Make a fresh final state\n",
        "    f = NxtStateStr()\n",
        "    F = set({ f })\n",
        "    return mk_nfa(Q     = Q0 | F,\n",
        "                  Sigma = set({a}),\n",
        "                  Delta = { (q0,a): F },\n",
        "                  Q0    = Q0,\n",
        "                  F     = F)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXLKVYKzv-EW"
      },
      "outputs": [],
      "source": [
        "def attrDyadicInfix(op, attr1, attr3):         # <== this is what prints the parse-tree\n",
        "    ast  = (op, (attr1['ast'], attr3['ast']))  # <== for an infix operator\n",
        "\n",
        "    nlin1 = attr1['dig']['nl']\n",
        "    nlin3 = attr3['dig']['nl']\n",
        "    nlin  = nlin1 + nlin3\n",
        "\n",
        "    elin1 = attr1['dig']['el']\n",
        "    elin3 = attr3['dig']['el']\n",
        "    elin  = elin1 + elin3\n",
        "\n",
        "    rootin1 = nlin1[0]\n",
        "    rootin3 = nlin3[0]\n",
        "\n",
        "    root   = NxtStateStr(\"R1\"+op+\"R2\"+\"_\") # NxtStateStr(\"$_\")\n",
        "    left   = rootin1\n",
        "    middle = NxtStateStr(op+\"_\")\n",
        "    right  = rootin3\n",
        "\n",
        "    return {'ast' : ast,\n",
        "            'dig' : {'nl' : [ root, left, middle, right ] + nlin,\n",
        "                     'el' : elin + [ (root, left),\n",
        "                                     (root, middle),\n",
        "                                     (root, right) ]\n",
        "                     }}\n",
        "\n",
        "\n",
        "def drawPT(nfa_ast_nl_el, comment=\"PT\"):\n",
        "    \"\"\"Given an (nfa, ast, nl, el) quadruple where nl is the node and el the edge-list,\n",
        "       draw the Parse Tree by returning a dot object. Also return the NFA dot object.\n",
        "    \"\"\"\n",
        "    (nfa, ast, nl, el) = nfa_ast_nl_el\n",
        "    print(\"Drawing AST for \", ast)\n",
        "    dotObj_pt = Digraph(comment)\n",
        "    dotObj_pt.graph_attr['rankdir'] = 'TB'\n",
        "    for n in nl:\n",
        "        prNam = n.split('_')[0]\n",
        "        dotObj_pt.node(n, prNam, shape=\"oval\", peripheries=\"1\")\n",
        "    for e in el:\n",
        "        dotObj_pt.edge(e[0], e[1])\n",
        "    return (dotObj_nfa(nfa), dotObj_pt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "run_control": {
          "frozen": false,
          "read_only": false
        },
        "id": "_Xc5eSOgv-EY"
      },
      "source": [
        "# Now run these cells and then answer the questions that follow these cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Lj4zQc3v-EY"
      },
      "outputs": [],
      "source": [
        "parseRE(\"''\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YihclDOQv-EZ"
      },
      "outputs": [],
      "source": [
        "(n,t) = drawPT(parseRE(\"''\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gxuyAkDv-Ef"
      },
      "outputs": [],
      "source": [
        "n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lAEWuELv-Ef"
      },
      "outputs": [],
      "source": [
        "t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfPYGwTvv-Eg"
      },
      "outputs": [],
      "source": [
        "(n1,t1) = drawPT(parseRE(\"(a*b*+cc)*\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WD3ZFCLqv-Eg"
      },
      "outputs": [],
      "source": [
        "(n2,t2) = drawPT(parseRE(\"(a*b)*+cc*\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFFGQOQ7v-Eh"
      },
      "outputs": [],
      "source": [
        "n1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EGfy6lMhv-Eh"
      },
      "outputs": [],
      "source": [
        "t1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6fQO27Vv-Ei"
      },
      "outputs": [],
      "source": [
        "n2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yqP-h4Tv-Ei"
      },
      "outputs": [],
      "source": [
        "t2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzb76-h5v-Ej"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vF2JSTSJv-Ej"
      },
      "source": [
        "\n",
        "# YOUR QUESTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkaNeCmgv-Ek"
      },
      "source": [
        "# Q1: Run this notebook as follows\n",
        "\n",
        "## 1) Restart this notebook if you want a \"fresh\" look. Then remove the parsetab.py file and the  __pycache__/ folder, again if things are confusing (else, no need). These are found under the \"File Icon\" tab on Colab (click to expand that icon on the left, and then nuke those files/folders and rerun the notebook). Again these are not essential steps for the most part - but good to do in case the remaining steps in this notebook give you trouble.\n",
        "\n",
        "## 2) Run all the cells (ignore warnings such as this)\n",
        "\n",
        "#### WARNING: ../../../../jove/TransitionSelectors.py:22: Possible grammar rule 'fn_range' defined without p_ prefix\n",
        "\n",
        "## 3) Look at the productions (the ```p_``` functions) present earlier in this notebook (example: p_expression_plus, and then the others after it) and write down a context-free grammar for parsing regular expressions that has been encoded in this Jove notebook.\n",
        "\n",
        "### YOUR ANSWER may please be written in this style, (inventing suitable abbreviations to express the High-level Rule)\n",
        "\n",
        "* expression : expression PLUS catexpression\n",
        "  - High-level Rule: R -> R + C  \n",
        "  \n",
        "* Do this for all the rules\n",
        "\n",
        "* When you have things like LPAREN, look up how the token was encoded, and write `(` instead in the High-level Rule. This way, things become a bit more readable than just seeing LPAREN, RPAREN, etc.\n",
        "\n",
        "* In summary, for this \"Q1\" part of the answer, your are to produce a neat-looking CFG which consists of high-level rules as above. By looking at those collection of rules, one should see clearly how we have specified the grammar for regular expression-parsing.\n",
        "\n",
        "# PLACE YOUR ANSWERS FOR Q1 BELOW IN THE SPACE PROVIDED\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "================\n",
        "... CFG RULES HERE ... REPLACE THIS LINE ...\n",
        "================"
      ],
      "metadata": {
        "id": "Jd8URmJw4dY8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USH15lDOv-Ek"
      },
      "source": [
        "# Q2: Execute these commands:\n",
        "\n",
        "* (n1,t1) = ```drawPT(parseRE(\"(a*b*+cc)*\"))```\n",
        "\n",
        "* (n2,t2) = ```drawPT(parseRE(\"(a*b)*+cc*\"))```\n",
        "\n",
        "## By comparing n1 and t1, justify that the correct NFA formation rules have been followed. Repeat for n2 and t2. YOUR JUSTIFICATION must consist of EXACTLY the following two sentencs with the details filled in.\n",
        "\n",
        "\n",
        "1) *I observe that the root node for the first regular expression (RE) is SUCH AND SUCH and that is because the RE was parsed as by applying the STAR operator a, and then b, and finally to FILL THIS PART SHOWING WHICH sub-regular-expression the third STAR operator was applied to.*\n",
        "\n",
        "2) *For the second RE, the last STAR was applied to DESCRIBE IN ONE SENTENCE.*\n",
        "\n",
        "3) *I acknowledge that I now fully understand how parseRE works. And I can see the same method being usd in file Def_RE2NFA.py in the jove/ folder of Jove. In both cases, the parse() function depends on a parser generated as per identical context-free grammar rules.*\n",
        "\n",
        "**For this step, you must click on the file icon, find the Jove files on the left-tab, locate Def_RE2NFA.py, download that file, and take a look inside that file. Thus your answer merely is the I acknowledge part, but you must have done these steps! We trust you, as we believe you want to learn these practical matters (you may be quizzed later in an actual exam to check if you did this).**\n",
        "\n",
        "\n",
        "# PLACE YOUR ANSWERS FOR Q2 BELOW IN THE SPACE PROVIDED\n",
        "\n",
        "==============\n",
        "... YOUR ANSWER REPLACES THIS LINE ....\n",
        "==============\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJYZtOUjv-Ek"
      },
      "source": [
        "# Q3: Explain the workings of all mk_X_nfa functions (with mk_star_nfa explained well).\n",
        "\n",
        "\n",
        "## *REQUIRED ANSWER*:\n",
        "\n",
        "## EXPLAIN HOW the code below for mk_star_nfa takes the NFA for ```R``` and produces an NFA for ```R*```.  The code you paste below can vary - but do pick up related code and paste below.\n",
        "\n",
        "   1) Introduce new (single) start+final state IF.Let Q0 = set({ IF }). THIS HAPPENS in THESE LINES OF CODE (paste the lines of code involved)\n",
        "\n",
        "    HERE\n",
        "\n",
        "   2) Move on epsilon from IF to the set N[Q0].\n",
        "\n",
        "   THIS HAPPENS in THESE LINES OF CODE (paste the lines of code involved)\n",
        "\n",
        "    HERE\n",
        "\n",
        "  3) Make N[F] non-final.\n",
        "\n",
        "  THIS HAPPENS in THESE LINES OF CODE (paste the lines of code involved)\n",
        "\n",
        "    HERE\n",
        "\n",
        "  4) Spin back from every state in N[F] to Q0.\n",
        "\n",
        "  THIS HAPPENS in THESE LINES OF CODE (paste the lines of code involved)\n",
        "\n",
        "    HERE\n",
        "\n",
        "  5) Return the final NFA.\n",
        "\n",
        "     HERE\n",
        "\n",
        "\n",
        "SIMILARLY, in your answer please mention at least something about these cases:\n",
        "\n",
        "* mk_cat_nfa is doing concatenation of the NFA of the two REs being concatenated,\n",
        "\n",
        "* mk_plus_nfa is doing the union (OR) of the two NFA,\n",
        "\n",
        "* and other mk_X_nfa are synthesizing primitive NFA.\n",
        "\n",
        "All these are following the textbook algorithms.\n",
        "\n",
        "```\n",
        "def mk_star_nfa(N):\n",
        "    '''Given an NFA, make its star.\n",
        "    '''\n",
        "    #\n",
        "    delta_accum = dict({})\n",
        "    IF = NxtStateStr()\n",
        "    Q0 = set({ IF }) # new set of start + final states\n",
        "    # Jump from IF to N's start state set\n",
        "    delta_accum.update({ (IF,\"\"): N[\"Q0\"] })\n",
        "    delta_accum.update(N[\"Delta\"])\n",
        "    #\n",
        "    for f in N[\"F\"]:\n",
        "        # N's final states may already have epsilon moves to\n",
        "        # other N-states!\n",
        "        # Expand the target of such jumps to include Q0 also.\n",
        "        if (f, \"\") in N[\"Delta\"]:\n",
        "            delta_accum.update({ (f, \"\"): (Q0 | N[\"Delta\"][(f, \"\")]) })\n",
        "        else:\n",
        "            delta_accum.update({ (f, \"\"): Q0 })\n",
        "    #\n",
        "    return mk_nfa(Q     = N[\"Q\"] | Q0,\n",
        "                  Sigma = N[\"Sigma\"],\n",
        "                  Delta = delta_accum,\n",
        "                  Q0    = Q0,\n",
        "                  F     = Q0)\n",
        "                  ```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lrHKuyYv-Ek"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hbw2D2214YD7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "12px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 4,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false,
      "widenNotebook": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}